general:
  debug: false

train:
  mixup:
    enable: false

logger:
  csv_logger:
    enable: true

  wandb_logger:
    enable: true
    group: exp_000

trainer:
  accumulate_grad_batches: 1
  precision: 16
  max_epochs: 20 # schduler
  resume_from_checkpoint: None
  stochastic_weight_avg: false

preprocess:
  base_dir: ../../data
  image_dir: train/image
  test_image_dir: test/image
  train_csv: csv/train.csv
  test_csv: csv/test.csv
  fold:
    name: StratifiedKFold
    n_splits: 5
    group: group # For GroupKFold

dataset:
  train_csv: train.csv
  test_csv: test.csv
  id: id
  target: target
  store_train: true
  store_valid: true
  grayscale: false
  gradcam: false
  loader:
    batch_size: 32
    num_workers: 8

transforms:
  train_version: v1
  valid_version: v1
  params:
    height: 224
    width: 224
    p: 0.5

model:
  name: net
  params:
    base_model: swin_base_patch4_window7_224
    pretrained: true
    checkpoint_path:
    num_classes: 2
    neck_version:
    head_version: v1

optimizer:
  name: AdamW

scheduler:
  name: CosineAnnealingWarmRestarts
  interval: step # [step, epoch]
  monitor: val_loss # [val_loss, val_score]

loss:
  names: ["CrossEntropyLoss"]
  weights: [1]

metric:
  names: ["AUROC"]
